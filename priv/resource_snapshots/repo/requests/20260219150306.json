{
  "attributes": [
    {
      "default": "nil",
      "size": null,
      "type": "bigint",
      "source": "id",
      "references": null,
      "allow_nil?": false,
      "primary_key?": true,
      "generated?": true
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "custom_id",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "url",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "model",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "request_payload",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "bigint",
      "source": "request_payload_size",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "bigint",
      "source": "estimated_input_tokens",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "bigint",
      "source": "estimated_request_input_tokens",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "map",
      "source": "response_payload",
      "references": null,
      "allow_nil?": true,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "state",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "map",
      "source": "delivery_config",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "text",
      "source": "error_msg",
      "references": null,
      "allow_nil?": true,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "utc_datetime_usec",
      "source": "created_at",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "utc_datetime_usec",
      "source": "updated_at",
      "references": null,
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    },
    {
      "default": "nil",
      "size": null,
      "type": "bigint",
      "source": "batch_id",
      "references": {
        "name": "requests_batch_id_fkey",
        "table": "batches",
        "multitenancy": {
          "global": null,
          "attribute": null,
          "strategy": null
        },
        "destination_attribute": "id",
        "on_update": null,
        "primary_key?": true,
        "on_delete": "delete",
        "deferrable": false,
        "destination_attribute_default": null,
        "destination_attribute_generated": null
      },
      "allow_nil?": false,
      "primary_key?": false,
      "generated?": false
    }
  ],
  "table": "requests",
  "hash": "9FFC53B87A98AB0AD89223F5962A937E74D0EA4610D3B048D00617AFFF66CF73",
  "repo": "Elixir.Batcher.Repo",
  "multitenancy": {
    "global": null,
    "attribute": null,
    "strategy": null
  },
  "identities": [],
  "strict?": false,
  "custom_indexes": [
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "custom_id"
      ],
      "where": null,
      "unique": true,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "state"
      ],
      "where": null,
      "unique": false,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "batch_id"
      ],
      "where": null,
      "unique": false,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "batch_id",
        "state"
      ],
      "where": null,
      "unique": false,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "created_at"
      ],
      "where": null,
      "unique": false,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "updated_at"
      ],
      "where": null,
      "unique": false,
      "using": null
    },
    {
      "message": null,
      "name": null,
      "table": null,
      "include": null,
      "fields": [
        "batch_id",
        "created_at"
      ],
      "where": null,
      "unique": false,
      "using": null
    }
  ],
  "custom_statements": [
    {
      "name": "requests_after_insert_update_batch_counters",
      "up": "CREATE TRIGGER IF NOT EXISTS requests_after_insert_update_batch_counters\nAFTER INSERT ON requests\nBEGIN\n  UPDATE batches\n  SET\n    request_count = request_count + 1,\n    size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),\n    estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),\n    estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)\n  WHERE id = NEW.batch_id;\nEND;\n",
      "down": "DROP TRIGGER IF EXISTS requests_after_insert_update_batch_counters;",
      "code?": false
    },
    {
      "name": "requests_after_delete_update_batch_counters",
      "up": "CREATE TRIGGER IF NOT EXISTS requests_after_delete_update_batch_counters\nAFTER DELETE ON requests\nBEGIN\n  UPDATE batches\n  SET\n    request_count = request_count - 1,\n    size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),\n    estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),\n    estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)\n  WHERE id = OLD.batch_id;\nEND;\n",
      "down": "DROP TRIGGER IF EXISTS requests_after_delete_update_batch_counters;",
      "code?": false
    },
    {
      "name": "requests_after_update_same_batch_update_counters",
      "up": "CREATE TRIGGER IF NOT EXISTS requests_after_update_same_batch_update_counters\nAFTER UPDATE OF request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests\nWHEN OLD.batch_id = NEW.batch_id\nBEGIN\n  UPDATE batches\n  SET\n    size_bytes = size_bytes + (COALESCE(NEW.request_payload_size, 0) - COALESCE(OLD.request_payload_size, 0)),\n    estimated_input_tokens_total = estimated_input_tokens_total + (COALESCE(NEW.estimated_input_tokens, 0) - COALESCE(OLD.estimated_input_tokens, 0)),\n    estimated_request_input_tokens_total = estimated_request_input_tokens_total + (COALESCE(NEW.estimated_request_input_tokens, 0) - COALESCE(OLD.estimated_request_input_tokens, 0))\n  WHERE id = NEW.batch_id;\nEND;\n",
      "down": "DROP TRIGGER IF EXISTS requests_after_update_same_batch_update_counters;",
      "code?": false
    },
    {
      "name": "requests_after_update_move_batch_update_counters",
      "up": "CREATE TRIGGER IF NOT EXISTS requests_after_update_move_batch_update_counters\nAFTER UPDATE OF batch_id, request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests\nWHEN OLD.batch_id != NEW.batch_id\nBEGIN\n  UPDATE batches\n  SET\n    request_count = request_count - 1,\n    size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),\n    estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),\n    estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)\n  WHERE id = OLD.batch_id;\n\n  UPDATE batches\n  SET\n    request_count = request_count + 1,\n    size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),\n    estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),\n    estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)\n  WHERE id = NEW.batch_id;\nEND;\n",
      "down": "DROP TRIGGER IF EXISTS requests_after_update_move_batch_update_counters;",
      "code?": false
    }
  ],
  "base_filter": null,
  "has_create_action": true
}