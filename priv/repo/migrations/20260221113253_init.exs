defmodule Batcher.Repo.Migrations.Init do
  @moduledoc """
  Updates resources based on their most recent snapshots.

  This file was autogenerated with `mix ash_postgres.generate_migrations`
  """

  use Ecto.Migration

  def up do
    create table(:settings, primary_key: false) do
      add :id, :bigserial, null: false, primary_key: true
      add :name, :text, null: false, default: "openai_rate_limits"
      add :model_token_overrides, :map, null: false, default: %{}

      add :inserted_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :updated_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")
    end

    create unique_index(:settings, [:name], name: "settings_unique_settings_name_index")

    create table(:requests, primary_key: false) do
      add :id, :bigserial, null: false, primary_key: true
      add :custom_id, :text, null: false
      add :url, :text, null: false
      add :model, :text, null: false
      add :request_payload, :text, null: false
      add :request_payload_size, :bigint, null: false
      add :estimated_input_tokens, :bigint, null: false, default: 0
      add :estimated_request_input_tokens, :bigint, null: false, default: 0
      add :response_payload, :map
      add :state, :text, null: false, default: "pending"
      add :delivery_config, :map, null: false
      add :error_msg, :text
      add :delivery_attempt_count, :bigint, null: false, default: 0

      add :created_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :updated_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :batch_id, :bigint, null: false
    end

    create index(:requests, [:batch_id, :created_at])

    create index(:requests, [:updated_at])

    create index(:requests, [:created_at])

    create index(:requests, [:batch_id, :state])

    create index(:requests, [:batch_id])

    create index(:requests, [:state])

    create index(:requests, [:custom_id], unique: true)

    create table(:request_delivery_attempts, primary_key: false) do
      add :id, :bigserial, null: false, primary_key: true
      add :attempt_number, :bigint, null: false
      add :outcome, :text, null: false
      add :delivery_config, :map, null: false
      add :error_msg, :text

      add :attempted_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :request_id,
          references(:requests,
            column: :id,
            name: "request_delivery_attempts_request_id_fkey",
            type: :bigint,
            prefix: "public",
            on_delete: :delete_all
          ),
          null: false
    end

    create index(:request_delivery_attempts, [:request_id, :attempt_number], unique: true)

    create index(:request_delivery_attempts, [:request_id, :attempted_at])

    create index(:request_delivery_attempts, [:request_id])

    create table(:batches, primary_key: false) do
      add :id, :bigserial, null: false, primary_key: true
    end

    alter table(:requests) do
      modify :batch_id,
             references(:batches,
               column: :id,
               name: "requests_batch_id_fkey",
               type: :bigint,
               prefix: "public",
               on_delete: :delete_all
             )
    end

    alter table(:batches) do
      add :state, :text, null: false, default: "building"
      add :openai_input_file_id, :text
      add :openai_output_file_id, :text
      add :openai_error_file_id, :text
      add :openai_batch_id, :text
      add :openai_status_last_checked_at, :utc_datetime
      add :openai_requests_completed, :bigint
      add :openai_requests_failed, :bigint
      add :openai_requests_total, :bigint
      add :url, :text, null: false
      add :model, :text, null: false
      add :request_count, :bigint, null: false, default: 0
      add :size_bytes, :bigint, null: false, default: 0
      add :estimated_input_tokens_total, :bigint, null: false, default: 0
      add :estimated_request_input_tokens_total, :bigint, null: false, default: 0
      add :capacity_last_checked_at, :utc_datetime
      add :capacity_wait_reason, :text
      add :waiting_for_capacity_since_at, :utc_datetime
      add :error_msg, :text
      add :token_limit_retry_attempts, :bigint, default: 0
      add :token_limit_retry_next_at, :utc_datetime
      add :token_limit_retry_last_error, :text
      add :input_tokens, :bigint
      add :cached_tokens, :bigint
      add :reasoning_tokens, :bigint
      add :output_tokens, :bigint
      add :expires_at, :utc_datetime

      add :created_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :updated_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")
    end

    create index(:batches, [:expires_at])

    create index(:batches, [
             :state,
             :model,
             :token_limit_retry_next_at,
             :waiting_for_capacity_since_at,
             :id
           ])

    create index(:batches, [:state, :model, :url], name: "batches_state_model_url_index")

    create table(:batch_transitions, primary_key: false) do
      add :id, :bigserial, null: false, primary_key: true
      add :from, :text
      add :to, :text, null: false

      add :transitioned_at, :utc_datetime_usec,
        null: false,
        default: fragment("(now() AT TIME ZONE 'utc')")

      add :batch_id,
          references(:batches,
            column: :id,
            name: "batch_transitions_batch_id_fkey",
            type: :bigint,
            prefix: "public",
            on_delete: :delete_all
          ),
          null: false
    end

    create index(:batch_transitions, [:batch_id, :transitioned_at])

    create index(:batch_transitions, [:batch_id])

    execute("""
    UPDATE batches
    SET
      request_count = (
        SELECT COUNT(*)
        FROM requests
        WHERE requests.batch_id = batches.id
      ),
      estimated_input_tokens_total = COALESCE((
        SELECT SUM(estimated_input_tokens)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0),
      estimated_request_input_tokens_total = COALESCE((
        SELECT SUM(estimated_request_input_tokens)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0),
      size_bytes = COALESCE((
        SELECT SUM(request_payload_size)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0)
    """)

    execute("""
    CREATE OR REPLACE FUNCTION requests_after_insert_update_batch_counters_fn()
    RETURNS trigger AS $$
    BEGIN
      UPDATE batches
      SET
        request_count = request_count + 1,
        size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)
      WHERE id = NEW.batch_id;

      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
    """)

    execute("""
    CREATE TRIGGER requests_after_insert_update_batch_counters
    AFTER INSERT ON requests
    FOR EACH ROW
    EXECUTE FUNCTION requests_after_insert_update_batch_counters_fn();
    """)

    execute("""
    CREATE OR REPLACE FUNCTION requests_after_delete_update_batch_counters_fn()
    RETURNS trigger AS $$
    BEGIN
      UPDATE batches
      SET
        request_count = request_count - 1,
        size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)
      WHERE id = OLD.batch_id;

      RETURN OLD;
    END;
    $$ LANGUAGE plpgsql;
    """)

    execute("""
    CREATE TRIGGER requests_after_delete_update_batch_counters
    AFTER DELETE ON requests
    FOR EACH ROW
    EXECUTE FUNCTION requests_after_delete_update_batch_counters_fn();
    """)

    execute("""
    CREATE OR REPLACE FUNCTION requests_after_update_same_batch_update_counters_fn()
    RETURNS trigger AS $$
    BEGIN
      IF OLD.batch_id = NEW.batch_id THEN
        UPDATE batches
        SET
          size_bytes = size_bytes + (COALESCE(NEW.request_payload_size, 0) - COALESCE(OLD.request_payload_size, 0)),
          estimated_input_tokens_total = estimated_input_tokens_total + (COALESCE(NEW.estimated_input_tokens, 0) - COALESCE(OLD.estimated_input_tokens, 0)),
          estimated_request_input_tokens_total = estimated_request_input_tokens_total + (COALESCE(NEW.estimated_request_input_tokens, 0) - COALESCE(OLD.estimated_request_input_tokens, 0))
        WHERE id = NEW.batch_id;
      END IF;

      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
    """)

    execute("""
    CREATE TRIGGER requests_after_update_same_batch_update_counters
    AFTER UPDATE OF request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests
    FOR EACH ROW
    EXECUTE FUNCTION requests_after_update_same_batch_update_counters_fn();
    """)

    execute("""
    CREATE OR REPLACE FUNCTION requests_after_update_move_batch_update_counters_fn()
    RETURNS trigger AS $$
    BEGIN
      IF OLD.batch_id != NEW.batch_id THEN
        UPDATE batches
        SET
          request_count = request_count - 1,
          size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),
          estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),
          estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)
        WHERE id = OLD.batch_id;

        UPDATE batches
        SET
          request_count = request_count + 1,
          size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),
          estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),
          estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)
        WHERE id = NEW.batch_id;
      END IF;

      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
    """)

    execute("""
    CREATE TRIGGER requests_after_update_move_batch_update_counters
    AFTER UPDATE OF batch_id, request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests
    FOR EACH ROW
    EXECUTE FUNCTION requests_after_update_move_batch_update_counters_fn();
    """)

    execute("""
    CREATE OR REPLACE FUNCTION request_delivery_attempts_after_insert_update_request_attempt_count_fn()
    RETURNS trigger AS $$
    BEGIN
      UPDATE requests
      SET delivery_attempt_count = delivery_attempt_count + 1
      WHERE id = NEW.request_id;

      RETURN NEW;
    END;
    $$ LANGUAGE plpgsql;
    """)

    execute("""
    CREATE TRIGGER request_delivery_attempts_after_insert_update_request_attempt_count
    AFTER INSERT ON request_delivery_attempts
    FOR EACH ROW
    EXECUTE FUNCTION request_delivery_attempts_after_insert_update_request_attempt_count_fn();
    """)
  end

  def down do
    execute("""
    DROP TRIGGER IF EXISTS request_delivery_attempts_after_insert_update_request_attempt_count ON request_delivery_attempts;
    """)

    execute("""
    DROP FUNCTION IF EXISTS request_delivery_attempts_after_insert_update_request_attempt_count_fn();
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_update_move_batch_update_counters ON requests;
    """)

    execute("""
    DROP FUNCTION IF EXISTS requests_after_update_move_batch_update_counters_fn();
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_update_same_batch_update_counters ON requests;
    """)

    execute("""
    DROP FUNCTION IF EXISTS requests_after_update_same_batch_update_counters_fn();
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_delete_update_batch_counters ON requests;
    """)

    execute("""
    DROP FUNCTION IF EXISTS requests_after_delete_update_batch_counters_fn();
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_insert_update_batch_counters ON requests;
    """)

    execute("""
    DROP FUNCTION IF EXISTS requests_after_insert_update_batch_counters_fn();
    """)

    execute("""
    SELECT 1;
    """)

    drop constraint(:batch_transitions, "batch_transitions_batch_id_fkey")

    drop_if_exists index(:batch_transitions, [:batch_id])

    drop_if_exists index(:batch_transitions, [:batch_id, :transitioned_at])

    drop table(:batch_transitions)

    drop_if_exists index(:batches, [:state, :model, :url], name: "batches_state_model_url_index")

    drop_if_exists index(:batches, [
                     :state,
                     :model,
                     :token_limit_retry_next_at,
                     :waiting_for_capacity_since_at,
                     :id
                   ])

    drop_if_exists index(:batches, [:expires_at])

    alter table(:batches) do
      remove :updated_at
      remove :created_at
      remove :expires_at
      remove :output_tokens
      remove :reasoning_tokens
      remove :cached_tokens
      remove :input_tokens
      remove :token_limit_retry_last_error
      remove :token_limit_retry_next_at
      remove :token_limit_retry_attempts
      remove :error_msg
      remove :waiting_for_capacity_since_at
      remove :capacity_wait_reason
      remove :capacity_last_checked_at
      remove :estimated_request_input_tokens_total
      remove :estimated_input_tokens_total
      remove :size_bytes
      remove :request_count
      remove :model
      remove :url
      remove :openai_requests_total
      remove :openai_requests_failed
      remove :openai_requests_completed
      remove :openai_status_last_checked_at
      remove :openai_batch_id
      remove :openai_error_file_id
      remove :openai_output_file_id
      remove :openai_input_file_id
      remove :state
    end

    drop constraint(:requests, "requests_batch_id_fkey")

    alter table(:requests) do
      modify :batch_id, :bigint
    end

    drop table(:batches)

    drop constraint(:request_delivery_attempts, "request_delivery_attempts_request_id_fkey")

    drop_if_exists index(:request_delivery_attempts, [:request_id])

    drop_if_exists index(:request_delivery_attempts, [:request_id, :attempted_at])

    drop_if_exists index(:request_delivery_attempts, [:request_id, :attempt_number])

    drop table(:request_delivery_attempts)

    drop_if_exists index(:requests, [:custom_id])

    drop_if_exists index(:requests, [:state])

    drop_if_exists index(:requests, [:batch_id])

    drop_if_exists index(:requests, [:batch_id, :state])

    drop_if_exists index(:requests, [:created_at])

    drop_if_exists index(:requests, [:updated_at])

    drop_if_exists index(:requests, [:batch_id, :created_at])

    drop table(:requests)

    drop_if_exists unique_index(:settings, [:name], name: "settings_unique_settings_name_index")

    drop table(:settings)
  end
end
