defmodule Batcher.Repo.Migrations.Init do
  @moduledoc """
  Updates resources based on their most recent snapshots.

  This file was autogenerated with `mix ash_sqlite.generate_migrations`
  """

  use Ecto.Migration

  def up do
    create table(:settings, primary_key: false) do
      add :updated_at, :utc_datetime_usec, null: false
      add :inserted_at, :utc_datetime_usec, null: false
      add :model_token_overrides, :map, null: false, default: %{}
      add :name, :text, null: false
      add :id, :bigserial, null: false, primary_key: true
    end

    create unique_index(:settings, [:name], name: "settings_unique_settings_name_index")

    create table(:requests, primary_key: false) do
      add :batch_id,
          references(:batches,
            column: :id,
            name: "requests_batch_id_fkey",
            type: :bigint,
            on_delete: :delete_all
          ),
          null: false

      add :updated_at, :utc_datetime_usec, null: false
      add :created_at, :utc_datetime_usec, null: false
      add :error_msg, :text
      add :delivery_config, :map, null: false
      add :state, :text, null: false
      add :response_payload, :map
      add :estimated_request_input_tokens, :bigint, null: false
      add :estimated_input_tokens, :bigint, null: false
      add :request_payload_size, :bigint, null: false
      add :request_payload, :text, null: false
      add :model, :text, null: false
      add :url, :text, null: false
      add :custom_id, :text, null: false
      add :id, :bigserial, null: false, primary_key: true
    end

    create table(:request_delivery_attempts, primary_key: false) do
      add :request_id,
          references(:requests,
            column: :id,
            name: "request_delivery_attempts_request_id_fkey",
            type: :bigint,
            on_delete: :delete_all
          ),
          null: false

      add :attempted_at, :utc_datetime_usec, null: false
      add :error_msg, :text
      add :delivery_config, :map, null: false
      add :outcome, :text, null: false
      add :id, :bigserial, null: false, primary_key: true
    end

    create index(:request_delivery_attempts, ["request_id", "attempted_at"])

    create index(:request_delivery_attempts, ["request_id"])

    create table(:batches, primary_key: false) do
      add :updated_at, :utc_datetime_usec, null: false
      add :created_at, :utc_datetime_usec, null: false
      add :expires_at, :utc_datetime
      add :output_tokens, :bigint
      add :reasoning_tokens, :bigint
      add :cached_tokens, :bigint
      add :input_tokens, :bigint
      add :token_limit_retry_last_error, :text
      add :token_limit_retry_next_at, :utc_datetime
      add :token_limit_retry_attempts, :bigint, default: 0
      add :error_msg, :text
      add :waiting_for_capacity_since_at, :utc_datetime
      add :capacity_wait_reason, :text
      add :capacity_last_checked_at, :utc_datetime
      add :estimated_request_input_tokens_total, :bigint, null: false, default: 0
      add :estimated_input_tokens_total, :bigint, null: false, default: 0
      add :size_bytes, :bigint, null: false, default: 0
      add :request_count, :bigint, null: false, default: 0
      add :model, :text, null: false
      add :url, :text, null: false
      add :openai_requests_total, :bigint
      add :openai_requests_failed, :bigint
      add :openai_requests_completed, :bigint
      add :openai_status_last_checked_at, :utc_datetime
      add :openai_batch_id, :text
      add :openai_error_file_id, :text
      add :openai_output_file_id, :text
      add :openai_input_file_id, :text
      add :state, :text, null: false
      add :id, :bigserial, null: false, primary_key: true
    end

    create index(:requests, ["batch_id", "created_at"])

    create index(:requests, ["updated_at"])

    create index(:requests, ["created_at"])

    create index(:requests, ["batch_id", "state"])

    create index(:requests, ["batch_id"])

    create index(:requests, ["state"])

    create index(:requests, ["custom_id"], unique: true)

    create index(:batches, ["expires_at"])

    create index(:batches, [
             "state",
             "model",
             "token_limit_retry_next_at",
             "waiting_for_capacity_since_at",
             "id"
           ])

    create index(:batches, ["state", "model", "url"], name: "batches_state_model_url_index")

    create table(:batch_transitions, primary_key: false) do
      add :batch_id,
          references(:batches,
            column: :id,
            name: "batch_transitions_batch_id_fkey",
            type: :bigint,
            on_delete: :delete_all
          ),
          null: false

      add :transitioned_at, :utc_datetime_usec, null: false
      add :to, :text, null: false
      add :from, :text
      add :id, :bigserial, null: false, primary_key: true
    end

    create index(:batch_transitions, ["batch_id", "transitioned_at"])

    create index(:batch_transitions, ["batch_id"])

    execute("""
    UPDATE batches
    SET
      request_count = (
        SELECT COUNT(*)
        FROM requests
        WHERE requests.batch_id = batches.id
      ),
      estimated_input_tokens_total = COALESCE((
        SELECT SUM(estimated_input_tokens)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0),
      estimated_request_input_tokens_total = COALESCE((
        SELECT SUM(estimated_request_input_tokens)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0),
      size_bytes = COALESCE((
        SELECT SUM(request_payload_size)
        FROM requests
        WHERE requests.batch_id = batches.id
      ), 0)
    """)

    execute("""
    CREATE TRIGGER IF NOT EXISTS requests_after_insert_update_batch_counters
    AFTER INSERT ON requests
    BEGIN
      UPDATE batches
      SET
        request_count = request_count + 1,
        size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)
      WHERE id = NEW.batch_id;
    END;
    """)

    execute("""
    CREATE TRIGGER IF NOT EXISTS requests_after_delete_update_batch_counters
    AFTER DELETE ON requests
    BEGIN
      UPDATE batches
      SET
        request_count = request_count - 1,
        size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)
      WHERE id = OLD.batch_id;
    END;
    """)

    execute("""
    CREATE TRIGGER IF NOT EXISTS requests_after_update_same_batch_update_counters
    AFTER UPDATE OF request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests
    WHEN OLD.batch_id = NEW.batch_id
    BEGIN
      UPDATE batches
      SET
        size_bytes = size_bytes + (COALESCE(NEW.request_payload_size, 0) - COALESCE(OLD.request_payload_size, 0)),
        estimated_input_tokens_total = estimated_input_tokens_total + (COALESCE(NEW.estimated_input_tokens, 0) - COALESCE(OLD.estimated_input_tokens, 0)),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total + (COALESCE(NEW.estimated_request_input_tokens, 0) - COALESCE(OLD.estimated_request_input_tokens, 0))
      WHERE id = NEW.batch_id;
    END;
    """)

    execute("""
    CREATE TRIGGER IF NOT EXISTS requests_after_update_move_batch_update_counters
    AFTER UPDATE OF batch_id, request_payload_size, estimated_input_tokens, estimated_request_input_tokens ON requests
    WHEN OLD.batch_id != NEW.batch_id
    BEGIN
      UPDATE batches
      SET
        request_count = request_count - 1,
        size_bytes = size_bytes - COALESCE(OLD.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total - COALESCE(OLD.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total - COALESCE(OLD.estimated_request_input_tokens, 0)
      WHERE id = OLD.batch_id;

      UPDATE batches
      SET
        request_count = request_count + 1,
        size_bytes = size_bytes + COALESCE(NEW.request_payload_size, 0),
        estimated_input_tokens_total = estimated_input_tokens_total + COALESCE(NEW.estimated_input_tokens, 0),
        estimated_request_input_tokens_total = estimated_request_input_tokens_total + COALESCE(NEW.estimated_request_input_tokens, 0)
      WHERE id = NEW.batch_id;
    END;
    """)
  end

  def down do
    execute("""
    DROP TRIGGER IF EXISTS requests_after_update_move_batch_update_counters;
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_update_same_batch_update_counters;
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_delete_update_batch_counters;
    """)

    execute("""
    DROP TRIGGER IF EXISTS requests_after_insert_update_batch_counters;
    """)

    execute("""
    SELECT 1;
    """)

    drop_if_exists index(:batch_transitions, ["batch_id"],
                     name: "batch_transitions_batch_id_index"
                   )

    drop_if_exists index(:batch_transitions, ["batch_id", "transitioned_at"],
                     name: "batch_transitions_batch_id_transitioned_at_index"
                   )

    drop constraint(:batch_transitions, "batch_transitions_batch_id_fkey")

    drop table(:batch_transitions)

    drop_if_exists index(:batches, ["state", "model", "url"],
                     name: "batches_state_model_url_index"
                   )

    drop_if_exists index(
                     :batches,
                     [
                       "state",
                       "model",
                       "token_limit_retry_next_at",
                       "waiting_for_capacity_since_at",
                       "id"
                     ],
                     name:
                       "batches_state_model_token_limit_retry_next_at_waiting_for_capacity_since_at_id_index"
                   )

    drop_if_exists index(:batches, ["expires_at"], name: "batches_expires_at_index")

    drop_if_exists index(:requests, ["custom_id"], name: "requests_custom_id_index")

    drop_if_exists index(:requests, ["state"], name: "requests_state_index")

    drop_if_exists index(:requests, ["batch_id"], name: "requests_batch_id_index")

    drop_if_exists index(:requests, ["batch_id", "state"], name: "requests_batch_id_state_index")

    drop_if_exists index(:requests, ["created_at"], name: "requests_created_at_index")

    drop_if_exists index(:requests, ["updated_at"], name: "requests_updated_at_index")

    drop_if_exists index(:requests, ["batch_id", "created_at"],
                     name: "requests_batch_id_created_at_index"
                   )

    drop table(:batches)

    drop_if_exists index(:request_delivery_attempts, ["request_id"],
                     name: "request_delivery_attempts_request_id_index"
                   )

    drop_if_exists index(:request_delivery_attempts, ["request_id", "attempted_at"],
                     name: "request_delivery_attempts_request_id_attempted_at_index"
                   )

    drop constraint(:request_delivery_attempts, "request_delivery_attempts_request_id_fkey")

    drop table(:request_delivery_attempts)

    drop constraint(:requests, "requests_batch_id_fkey")

    drop table(:requests)

    drop_if_exists unique_index(:settings, [:name], name: "settings_unique_settings_name_index")

    drop table(:settings)
  end
end